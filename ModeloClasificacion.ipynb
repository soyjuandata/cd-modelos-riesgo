{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-image: url('https://i.pinimg.com/1200x/45/3a/06/453a06bdc2b2d27d8329857061537124.jpg'); \n",
    "            background-size: cover; \n",
    "            background-position: center; \n",
    "            padding: 30px; \n",
    "            text-align: center; \n",
    "            border-radius: 8px;\">\n",
    "    <h1 style=\"color: white; \n",
    "               font-size: 28px; \n",
    "               font-weight: bold; \n",
    "               text-shadow: 2px 2px 4px rgba(0,0,0,0.8), \n",
    "                            -1px -1px 2px rgba(0,0,0,0.8);\n",
    "               margin: 0;\n",
    "               font-family: 'Arial', sans-serif;\">\n",
    "        PROYECTO: MODELO DE RIESGO\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mar√≠a Jos√© Castillo Silva\n",
    "- Juan David Bocanegra Vargas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container{ width:98% }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Permite ajustar la anchura de la parte √∫til de la libreta (reduce los m√°rgenes) y omitir warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.display import HTML\n",
    "display(HTML(\"<style>.container{ width:98% }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Problema a Analizar\n",
    "\n",
    "# ¬øCu√°l es la probabilidad de riesgo de default asociada a cada cliente, dadas sus diferentes caracter√≠sticas?.\n",
    "\n",
    "La principal fuente de datos es Datacredito Experian, quienes env√≠an informaci√≥n de los clientes actuales de la Entidad, incluyendo las siguientes variables: ‚ÄúAcierta Advance‚Äù, score de cr√©dito del sector financiero, saldos, estados de productos crediticios y tambi√©n informaci√≥n demografica como edad, sexo, entre otras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Impacto del Problema\n",
    "\n",
    "Actualmente en las √°reas de riesgo de cr√©dito en el sector bancario, se definen constantemente pol√≠ticas que permiten soportar la toma de decisiones en la originaci√≥n  de productos, que en la medida de lo posible, est√©n enmarcadas en la agilidad y precisi√≥n de la respuesta a clientes, y vayan en l√≠nea con el apetito financiero propuesto por la Junta Directiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Datos, primer an√°lisis exploratorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalaci√≥n de Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install eli5\n",
    "#!pip install pandas\n",
    "#!pip install numpy\n",
    "#!pip install seaborn\n",
    "#!pip install yellowbrick\n",
    "#!pip install xgboost\n",
    "#!pip install shap\n",
    "#!pip install matplotlib\n",
    "#!pip install scikit-learn\n",
    "#!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar Librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U scikit-learn==1.5.2 imbalanced-learn==0.12.3 yellowbrick==1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# N√∫cleo cient√≠fico / utilidades\n",
    "# ===============================\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===============================\n",
    "# Modelado y validaci√≥n (scikit-learn)\n",
    "# ===============================\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, StratifiedKFold, RandomizedSearchCV, cross_val_score\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score, roc_curve, precision_recall_curve,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "\n",
    "# ===============================\n",
    "# Desbalanceo de clases (imbalanced-learn)\n",
    "# ===============================\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# ===============================\n",
    "# Gradient Boosting (XGBoost)\n",
    "# ===============================\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# ===============================\n",
    "# Estad√≠stica (SciPy y Statsmodels)\n",
    "# ===============================\n",
    "from scipy import stats\n",
    "from scipy.stats import shapiro, normaltest, ttest_ind, mannwhitneyu\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor  # VIF\n",
    "\n",
    "# ===============================\n",
    "# Otros apoyos\n",
    "# ===============================\n",
    "from collections import Counter\n",
    "\n",
    "# ===============================\n",
    "# Opcionales de interpretaci√≥n/visual\n",
    "# ===============================\n",
    "import shap\n",
    "from yellowbrick.classifier import ROCAUC, ConfusionMatrix, ClassificationReport\n",
    "import eli5\n",
    "\n",
    "# ===============================\n",
    "# Estilo de gr√°ficos\n",
    "# ===============================\n",
    "plt.style.use(\"ggplot\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('base_modelo_40k.csv', sep=',')\n",
    "datos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datos.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Inicialmente se contemplaron 40 variables en estudio, mixtas entre categ√≥ricas y num√©ricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza y Armonizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONVERSI√ìN TIPOS DE FORMATO\n",
    "datos['CRED_REESTRUCTURADO']=datos['CRED_REESTRUCTURADO'].astype('object')\n",
    "datos['TIENE_HIPOTECA']=datos['TIENE_HIPOTECA'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Conteo valores nulos\n",
    "datos.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Por criterio experto, se consideran no necesarias las variables asociadas a la identificaci√≥n del cliente, como el tipo de Id, el n√∫mero de identificaci√≥n y la fecha de evaluaci√≥n; tambi√©n se elimina la variable \"Acierta_plus\" ya que existe la variable \"Advance\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ELIMINAR COLUMNAS NO NECESARIAS\n",
    "datos=datos.drop(labels='ID',axis=1)\n",
    "datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dimensi√≥n base de datos\n",
    "print(datos.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An√°lisis Exploratorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La Variable de inter√©s es la variable llamada VAR_DEP, que es 1 si el cliente tuvo una mora mayor a 90 d√≠as en los doce meses siguientes al desembolso del credito y 0 si ha estado al d√≠a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Proporci√≥n de clientes en Mora\n",
    "datos.groupby('CLIENTE_MORA').size()/datos['CLIENTE_MORA'].count()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La base con 54.759 clientes, contiene un 7.08% de clientes en mora y un 92.92% de clientes al d√≠a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separaci√≥n de Bases\n",
    "datos_0 = datos[datos['CLIENTE_MORA'] == 0]\n",
    "datos_1 = datos[datos['CLIENTE_MORA'] == 1]\n",
    "\n",
    "#Funci√≥n de densidad \n",
    "datos_0.SCORE_DATACREDITO.plot.density(color='green',label='Clientes Al d√≠a') \n",
    "datos_1.SCORE_DATACREDITO.plot.density(color='red',label='Clientes en Mora')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Score Datacredito\")\n",
    "plt.ylabel('Probabilidad num√©rica')\n",
    "plt.title('Score Datacredito Clientes al d√≠a y en mora')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se evidencia que los clientes que han tenido una mora de 90 d√≠as o m√°s en los 12 ultimos meses tienen un Score Advance (c√°lculo por datacredito) menor a los clientes que han estado al d√≠a. Tambi√©n se resalta que, la mayor√≠a de clientes en mora tienen un Score Advance entre 500 a 850, en cambio los clientes que han estado al d√≠a tienen un score adnvance entre 650 a 950."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruebas estad√≠sticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de normalidad Shapiro-Wilk\n",
    "print(\"Prueba Shapiro-Wilk Poblaci√≥n al d√≠a:\",shapiro(datos_0['SCORE_DATACREDITO']))\n",
    "print(\"Prueba Shapiro-Wilk Poblaci√≥n en mora:\",shapiro(datos_1['SCORE_DATACREDITO']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diferencia de medias\n",
    "def dif_medias (df1, df2, alfa):\n",
    "    stat, p = ttest_ind(df1,df2, equal_var = False)\n",
    "    print(\"Statistic=%.3f, p=%.3f\" % (stat,p))\n",
    "\n",
    "dif_medias (datos_0['SCORE_DATACREDITO'], datos_1['SCORE_DATACREDITO'], 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba no parametrcia Mann-Whitney para comparar la variable ADVANCE en los dos grupos\n",
    "stat, p = mannwhitneyu(datos_0['SCORE_DATACREDITO'], datos_1['SCORE_DATACREDITO'], alternative='two-sided')\n",
    "\n",
    "print(\"Mann-Whitney U Test\")\n",
    "print(f\"Estad√≠stico U = {stat:.3f}, p-valor = {p:.3e}\")\n",
    "\n",
    "# Interpretaci√≥n r√°pida\n",
    "alpha = 0.05\n",
    "if p < alpha:\n",
    "    print(\"üëâ Se rechaza H0: Las distribuciones de ADVANCE en los dos grupos son diferentes.\")\n",
    "else:\n",
    "    print(\"üëâ No se rechaza H0: No hay evidencia de diferencia significativa entre los grupos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Existe evidencia estad√≠sticamente significativa para afirmar que las medias de la variable ADVANCE en los dos grupos comparados (datos_0 y datos_1) son diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_0.ANT_SF.plot.density(color='green',label='Clientes Al d√≠a') \n",
    "datos_1.ANT_SF.plot.density(color='red',label='Clientes en Mora')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Antig√ºedad Financiera\")\n",
    "plt.ylabel('Probabilidad num√©rica')\n",
    "plt.title('Antig√ºedad Financiera de Clientes al d√≠a y en mora')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se evidencia como lo clientes que estan al d√≠a tienden  a tener mayor antiguedad en el sector financiero a comparaci√≥n de los cliente en mora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba K-S\n",
    "stats.ks_2samp(datos_0['ANT_SF'], datos_1['ANT_SF'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Los clientes al d√≠a tienden a tener una mayor antig√ºedad en el sistema financiero que los clientes en mora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_0.EDAD.plot.density(color='green',label='Clientes Al d√≠a') \n",
    "datos_1.EDAD.plot.density(color='red',label='Clientes en Mora')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Edad\")\n",
    "plt.ylabel('Probabilidad num√©rica')\n",
    "plt.title('Edad Clientes al d√≠a y en mora')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Los clientes en mora tienden a concentrarse en edades entre los 30 a los 40 a√±os, en cambio los clientes al d√≠a tienden a ser de mayor edad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(datos['SEXO'], datos['CLIENTE_MORA'], normalize='index')*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se evidencia que las mujeres pagan mejor que los hombres, dado que el porcentaje de incumplimiento de las mujeres es 6.7% en cambio de los hombres es de 7.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_0.INGRESO.plot.density(color='green',label='Clientes Al d√≠a') \n",
    "datos_1.INGRESO.plot.density(color='red',label='Clientes en Mora')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Ingresos\")\n",
    "plt.ylabel('Probabilidad num√©rica')\n",
    "plt.title('Ingresos de Clientes al d√≠a y en mora')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se evidencia que no existen diferencias de ingreso respecto al incumplimiento de pago de los clientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datos_0.INGRESO.plot.density(color='green',label='Clientes Al d√≠a') \n",
    "datos_1.INGRESO.plot.density(color='red',label='Clientes en Mora')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Ingresos\")\n",
    "plt.ylabel('Probabilidad num√©rica')\n",
    "plt.title('Ingresos de Clientes al d√≠a y en mora')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlaci√≥n compacta con encabezados verticales sin superposici√≥n\n",
    "corr = datos.select_dtypes(include='number').corr().round(2)\n",
    "\n",
    "display(\n",
    "    corr.style\n",
    "        .format(\"{:.2f}\")\n",
    "        .background_gradient(cmap=\"BrBG\")\n",
    "        # fuente y padding peque√±os en todo\n",
    "        .set_properties(**{\"font-size\":\"8pt\", \"padding\":\"2px\"})\n",
    "        # estilos espec√≠ficos de encabezados\n",
    "        .set_table_styles([\n",
    "            # columnas: vertical, ancho fijo peque√±o, sin quiebre ni solape\n",
    "            {\"selector\":\"th.col_heading\",\n",
    "             \"props\":[\n",
    "                 (\"writing-mode\",\"vertical-rl\"),\n",
    "                 (\"text-orientation\",\"mixed\"),\n",
    "                 (\"width\",\"24px\"), (\"min-width\",\"24px\"), (\"max-width\",\"24px\"),\n",
    "                 (\"height\",\"140px\"),\n",
    "                 (\"white-space\",\"nowrap\"),\n",
    "                 (\"overflow\",\"hidden\"),\n",
    "                 (\"text-overflow\",\"clip\"),\n",
    "                 (\"font-size\",\"7pt\"),\n",
    "                 (\"padding\",\"6px 2px\")\n",
    "             ]},\n",
    "            # filas: fuente peque√±a\n",
    "            {\"selector\":\"th.row_heading\",\n",
    "             \"props\":[(\"font-size\",\"7pt\"), (\"white-space\",\"nowrap\")]}\n",
    "        ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En la matriz de correlaci√≥n se evidencia que las variables que m√°s estan relacionadas con la variable de incumplimiento de pago es el score Advance generado por Datacredito y en segunda medida variables como los saldos de los creditos, los estados de mora y la antiguedad en el sector financiero. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminaci√≥n de variables VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Solo num√©ricas y limpieza m√≠nima\n",
    "num = datos.select_dtypes(include='number').copy()\n",
    "num = num.dropna(axis=1, how='all')                 # quita columnas totalmente vac√≠as\n",
    "num = num.loc[:, num.nunique()>1]                   # quita columnas con varianza 0\n",
    "num = num.fillna(num.median(numeric_only=True))     # imputaci√≥n simple (si hay NA)\n",
    "\n",
    "# 2) Matriz para VIF (no necesita estandarizar)\n",
    "X = sm.add_constant(num, has_constant='add')\n",
    "\n",
    "# 3) Calcular VIF (omitimos la constante en el resultado)\n",
    "vif_vals = [variance_inflation_factor(X.values, i) for i in range(1, X.shape[1])]\n",
    "vifs = (pd.DataFrame({'Variable': num.columns, 'VIF': vif_vals})\n",
    "          .replace([np.inf, -np.inf], np.nan)\n",
    "          .sort_values('VIF', ascending=False)\n",
    "          .reset_index(drop=True))\n",
    "\n",
    "# 4) Mostrar\n",
    "display(vifs.style.format({'VIF':'{:.2f}'}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# X e y\n",
    "X = datos.drop(columns='CLIENTE_MORA')\n",
    "y = datos['CLIENTE_MORA']\n",
    "\n",
    "# Detecta columnas\n",
    "cat_cols = X.select_dtypes(include=['object','category']).columns.tolist()\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# OneHotEncoder compatible (1.2-1.5+)\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)  # sklearn ‚â•1.2\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)         # sklearn <1.2\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    ('num', RobustScaler(), num_cols),\n",
    "    ('cat', ohe, cat_cols)\n",
    "], remainder='drop')\n",
    "\n",
    "X_pre = preprocess.fit_transform(X)\n",
    "print(f\"Shape original: {X.shape} ‚Üí transformado: {X_pre.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partici√≥n Train Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 2025\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=seed, stratify=y, shuffle=True\n",
    ")\n",
    "\n",
    "# asegurar que preprocessing_pipeline exista\n",
    "try:\n",
    "    preprocessing_pipeline\n",
    "except NameError:\n",
    "    preprocessing_pipeline = preprocess\n",
    "\n",
    "print(f\"Split OK ‚Üí X_train: {X_train.shape}, X_test: {X_test.shape}, seed={seed}\")\n",
    "print(\"preprocessing_pipeline definido ‚úÖ\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de evaluaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelo(best_model, X_train, y_train, X_test, y_test, nombre=\"Modelo\", pos_label=1):\n",
    "    \"\"\"Imprime m√©tricas y devuelve un dict con resultados clave.\"\"\"\n",
    "    # Predicciones duras\n",
    "    pred_train = best_model.predict(X_train)\n",
    "    pred_test  = best_model.predict(X_test)\n",
    "\n",
    "    # Probabilidades para AUC y PR-AUC\n",
    "    if hasattr(best_model, \"predict_proba\"):\n",
    "        proba_test = best_model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        proba_test = best_model.decision_function(X_test)\n",
    "\n",
    "    # M√©tricas\n",
    "    train_acc    = accuracy_score(y_train, pred_train)\n",
    "    test_acc     = accuracy_score(y_test,  pred_test)\n",
    "    train_recall = recall_score(y_train, pred_train, pos_label=pos_label, zero_division=0)\n",
    "    test_recall  = recall_score(y_test,  pred_test,  pos_label=pos_label, zero_division=0)\n",
    "    train_prec   = precision_score(y_train, pred_train, pos_label=pos_label, zero_division=0)\n",
    "    test_prec    = precision_score(y_test,  pred_test,  pos_label=pos_label, zero_division=0)\n",
    "    roc_test     = roc_auc_score(y_test, proba_test)\n",
    "    pr_test      = average_precision_score(y_test, proba_test)\n",
    "\n",
    "    # Reporte\n",
    "    print(f\"=== {nombre} ===\")\n",
    "    print('Train Accuracy  : ', train_acc)\n",
    "    print('Test  Accuracy  : ', test_acc)\n",
    "    print('Train Recall    : ', train_recall)\n",
    "    print('Test  Recall    : ', test_recall)\n",
    "    print('Train Precision : ', train_prec)\n",
    "    print('Test  Precision : ', test_prec)\n",
    "    print('ROC AUC (test)  : ', roc_test)\n",
    "\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(confusion_matrix(y_test, pred_test))\n",
    "\n",
    "    print('\\nClassification Report:')\n",
    "    print(classification_report(y_test, pred_test, zero_division=0))\n",
    "\n",
    "    return {\n",
    "        \"train_acc\":    train_acc,\n",
    "        \"test_acc\":     test_acc,\n",
    "        \"train_recall\": train_recall,\n",
    "        \"test_recall\":  test_recall,\n",
    "        \"train_prec\":   train_prec,\n",
    "        \"test_prec\":    test_prec,\n",
    "        \"roc_auc\":      roc_test\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definicion Hiperpar√°metros y CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "seed = globals().get('seed', 42)\n",
    "\n",
    "param_grid = {\n",
    "    \"model\": [DecisionTreeClassifier(random_state=seed)],\n",
    "    \"model__criterion\": [\"gini\", \"entropy\"],\n",
    "    \"model__splitter\": [\"best\", \"random\"],\n",
    "    \"model__max_leaf_nodes\": [128, 256, 512, 1024],\n",
    "    \"model__max_depth\": list(map(int, np.linspace(4, 16, 32)))\n",
    "}\n",
    "\n",
    "scoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=seed, shuffle=True)\n",
    "n_iter = 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline base (sin balanceo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not any(v not in globals() for v in [\"X_train\",\"X_test\",\"y_train\",\"y_test\",\"preprocessing_pipeline\"]):\n",
    "    full_pipeline_steps = [\n",
    "        ('preprocessing_pipeline', preprocessing_pipeline),\n",
    "        ('model', DecisionTreeClassifier(random_state=seed))\n",
    "    ]\n",
    "    full_pipeline = Pipeline(steps=full_pipeline_steps)\n",
    "\n",
    "    grid_base = RandomizedSearchCV(\n",
    "        estimator=full_pipeline,\n",
    "        param_distributions=param_grid,\n",
    "        cv=kfold,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "        n_iter=n_iter,\n",
    "        refit=\"AUC\",\n",
    "        random_state=seed\n",
    "    )\n",
    "    best_model_base = grid_base.fit(X_train, y_train)\n",
    "    print(\">> Mejor AUC (CV) ‚Äì Base:\", best_model_base.best_score_)\n",
    "\n",
    "    # === M√©tricas adicionales: Recall y AUC en train y test ===\n",
    "    est = best_model_base.best_estimator_\n",
    "\n",
    "    # Predicciones duras\n",
    "    pred_train = est.predict(X_train)\n",
    "    pred_test  = est.predict(X_test)\n",
    "\n",
    "    # Scores probabil√≠sticos para AUC\n",
    "    if hasattr(est, \"predict_proba\"):\n",
    "        score_train = est.predict_proba(X_train)[:, 1]\n",
    "        score_test  = est.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        score_train = est.decision_function(X_train)\n",
    "        score_test  = est.decision_function(X_test)\n",
    "\n",
    "else:\n",
    "    print(\"‚õî Define X_train/X_test/y_train/y_test/preprocessing_pipeline antes de ejecutar esta celda.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling dentro del CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not any(v not in globals() for v in [\"X_train\",\"X_test\",\"y_train\",\"y_test\",\"preprocessing_pipeline\"]):\n",
    "    undersampler = RandomUnderSampler(random_state=seed)\n",
    "\n",
    "    pipe_under = ImbPipeline(steps=[\n",
    "        ('preprocessing_pipeline', preprocessing_pipeline),\n",
    "        ('sampler', undersampler),\n",
    "        ('model', DecisionTreeClassifier(random_state=seed))\n",
    "    ])\n",
    "\n",
    "    grid_under = RandomizedSearchCV(\n",
    "        estimator=pipe_under,\n",
    "        param_distributions=param_grid,\n",
    "        cv=kfold,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "        n_iter=n_iter,\n",
    "        refit=\"AUC\",\n",
    "        random_state=seed\n",
    "    )\n",
    "\n",
    "    best_model_under = grid_under.fit(X_train, y_train)\n",
    "    print(\">> Mejor AUC (CV) ‚Äì Undersampling:\", best_model_under.best_score_)\n",
    "else:\n",
    "    print(\"‚õî Define X_train/X_test/y_train/y_test/preprocessing_pipeline antes de ejecutar esta celda.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling dentro del CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not any(v not in globals() for v in [\"X_train\",\"X_test\",\"y_train\",\"y_test\",\"preprocessing_pipeline\"]):\n",
    "    oversampler = RandomOverSampler(random_state=seed)\n",
    "\n",
    "    pipe_over = ImbPipeline(steps=[\n",
    "        ('preprocessing_pipeline', preprocessing_pipeline),\n",
    "        ('sampler', oversampler),\n",
    "        ('model', DecisionTreeClassifier(random_state=seed))\n",
    "    ])\n",
    "\n",
    "    grid_over = RandomizedSearchCV(\n",
    "        estimator=pipe_over,\n",
    "        param_distributions=param_grid,\n",
    "        cv=kfold,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "        n_iter=n_iter,\n",
    "        refit=\"AUC\",\n",
    "        random_state=seed\n",
    "    )\n",
    "\n",
    "    best_model_over = grid_over.fit(X_train, y_train)\n",
    "    print(\">> Mejor AUC (CV) ‚Äì Oversampling:\", best_model_over.best_score_)\n",
    "else:\n",
    "    print(\"‚õî Define X_train/X_test/y_train/y_test/preprocessing_pipeline antes de ejecutar esta celda.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE dentro del CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import recall_score, roc_auc_score  # por si faltan\n",
    "\n",
    "if not any(v not in globals() for v in [\"X_train\",\"X_test\",\"y_train\",\"y_test\",\"preprocessing_pipeline\"]):\n",
    "    smote = SMOTE(random_state=seed, k_neighbors=5)  # puedes tunear k_neighbors\n",
    "\n",
    "    pipe_smote = ImbPipeline(steps=[\n",
    "        ('preprocessing_pipeline', preprocessing_pipeline),\n",
    "        ('sampler', smote),\n",
    "        ('model', DecisionTreeClassifier(random_state=seed))\n",
    "    ])\n",
    "\n",
    "    grid_smote = RandomizedSearchCV(\n",
    "        estimator=pipe_smote,\n",
    "        param_distributions=param_grid,\n",
    "        cv=kfold,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "        n_iter=n_iter,\n",
    "        refit=\"AUC\",\n",
    "        random_state=seed\n",
    "    )\n",
    "\n",
    "    best_model_smote = grid_smote.fit(X_train, y_train)\n",
    "    print(\">> Mejor AUC (CV) ‚Äì SMOTE:\", best_model_smote.best_score_)\n",
    "\n",
    "    # M√©tricas r√°pidas (train/test) para Recall y AUC\n",
    "    est = best_model_smote.best_estimator_\n",
    "    pred_train = est.predict(X_train)\n",
    "    pred_test  = est.predict(X_test)\n",
    "\n",
    "    if hasattr(est, \"predict_proba\"):\n",
    "        score_train = est.predict_proba(X_train)[:, 1]\n",
    "        score_test  = est.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        score_train = est.decision_function(X_train)\n",
    "        score_test  = est.decision_function(X_test)\n",
    "\n",
    "    print(f\"Train Recall: {recall_score(y_train, pred_train, zero_division=0):.4f} | \"\n",
    "          f\"Train AUC: {roc_auc_score(y_train, score_train):.4f}\")\n",
    "    print(f\"Test  Recall: {recall_score(y_test,  pred_test,  zero_division=0):.4f} | \"\n",
    "          f\"Test  AUC:  {roc_auc_score(y_test,  score_test):.4f}\")\n",
    "else:\n",
    "    print(\"‚õî Define X_train/X_test/y_train/y_test/preprocessing_pipeline antes de ejecutar esta celda.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validaciones finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 10. Validaciones finales (incluye SMOTE si existe) =====\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, recall_score, roc_auc_score, average_precision_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "models_to_eval = []\n",
    "if 'best_model_base'  in globals(): models_to_eval.append((\"√Årbol ‚Äì Base (sin balanceo)\", best_model_base.best_estimator_))\n",
    "if 'best_model_under' in globals(): models_to_eval.append((\"√Årbol ‚Äì Undersampling\",        best_model_under.best_estimator_))\n",
    "if 'best_model_over'  in globals(): models_to_eval.append((\"√Årbol ‚Äì Oversampling\",         best_model_over.best_estimator_))\n",
    "if 'best_model_smote' in globals(): models_to_eval.append((\"√Årbol ‚Äì SMOTE\",                best_model_smote.best_estimator_))\n",
    "\n",
    "if models_to_eval:\n",
    "    metrics_map = {}\n",
    "    for nombre, est in models_to_eval:\n",
    "        metrics_map[nombre] = evaluar_modelo(est, X_train, y_train, X_test, y_test, nombre=nombre)\n",
    "\n",
    "    # (opcional) dejar variables sueltas como antes:\n",
    "    if 'best_model_base'  in globals(): metrics_base  = metrics_map[\"√Årbol ‚Äì Base (sin balanceo)\"]\n",
    "    if 'best_model_under' in globals(): metrics_under = metrics_map[\"√Årbol ‚Äì Undersampling\"]\n",
    "    if 'best_model_over'  in globals(): metrics_over  = metrics_map[\"√Årbol ‚Äì Oversampling\"]\n",
    "    if 'best_model_smote' in globals(): metrics_smote = metrics_map[\"√Årbol ‚Äì SMOTE\"]\n",
    "else:\n",
    "    print(\"‚õî No hay modelos para evaluar. Ejecuta primero Base/Under/Over/SMOTE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escoger el mejor modelo y extraer el √°rbol final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidatos = []\n",
    "\n",
    "if 'best_model_base'  in globals() and 'metrics_base'  in globals():\n",
    "    candidatos.append((\"base\",  best_model_base,  metrics_base[\"test_recall\"]))\n",
    "if 'best_model_under' in globals() and 'metrics_under' in globals():\n",
    "    candidatos.append((\"under\", best_model_under, metrics_under[\"test_recall\"]))\n",
    "if 'best_model_over'  in globals() and 'metrics_over'  in globals():\n",
    "    candidatos.append((\"over\",  best_model_over,  metrics_over[\"test_recall\"]))\n",
    "if 'best_model_smote' in globals() and 'metrics_smote' in globals():\n",
    "    candidatos.append((\"smote\", best_model_smote, metrics_smote[\"test_recall\"]))\n",
    "\n",
    "if candidatos:\n",
    "    mejor_nombre, best_model, best_rec = max(candidatos, key=lambda x: x[2])\n",
    "    print(f\"\\n>>> Mejor enfoque seg√∫n Recall (test): {mejor_nombre.upper()} con Recall={best_rec:.4f}\")\n",
    "    dt_model = best_model.best_estimator_['model']\n",
    "    print(\"\\nHiperpar√°metros del √°rbol ganador:\\n\", dt_model.get_params())\n",
    "else:\n",
    "    print(\"‚õî No hay candidatos para comparar. Corre las celdas de entrenamiento/validaci√≥n primero.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curvas ROC y Precision-Recall del modelo ganador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, ConfusionMatrixDisplay,\n",
    "    roc_curve, roc_auc_score,\n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "\n",
    "# === Modelo ganador: best_model_under ===\n",
    "best_est = best_model_under.best_estimator_\n",
    "\n",
    "# Probabilidades y predicciones en test\n",
    "y_proba = best_est.predict_proba(X_test)[:,1]\n",
    "y_pred  = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "# === Matriz de confusi√≥n ===\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(cm).plot(cmap=\"Blues\")\n",
    "plt.title(\"Matriz de confusi√≥n ‚Äì Modelo UNDER (umbral 0.5)\")\n",
    "plt.show()\n",
    "\n",
    "# === Curva ROC ===\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"ROC (AUC={roc_auc:.3f})\", lw=2)\n",
    "plt.plot([0,1],[0,1],\"--\", color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate (Recall)\")\n",
    "plt.title(\"Curva ROC ‚Äì Modelo UNDER\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# === Curva Precision‚ÄìRecall ===\n",
    "prec, rec, _ = precision_recall_curve(y_test, y_proba)\n",
    "ap = average_precision_score(y_test, y_proba)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(rec, prec, label=f\"PR (AP={ap:.3f})\", lw=2, color=\"darkorange\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Curva Precision‚ÄìRecall ‚Äì Modelo UNDER\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modelo XGBOOST CON REGULARIZACION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanceo UNDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import pandas as pd\n",
    "\n",
    "under = RandomUnderSampler(sampling_strategy=1.0, random_state=seed)\n",
    "X_train_under, y_train_under = under.fit_resample(X_train, y_train)\n",
    "\n",
    "# Res√∫menes\n",
    "def resumen(y):\n",
    "    c = y.value_counts().sort_index()\n",
    "    p = y.value_counts(normalize=True).sort_index().mul(100).round(2)\n",
    "    return pd.DataFrame({\"count\": c, \"pct%\": p})\n",
    "\n",
    "print(\"UNDER aplicado\")\n",
    "print(f\"Tama√±o original   : {X_train.shape[0]} filas\")\n",
    "print(f\"Tama√±o balanceado : {X_train_under.shape[0]} filas\\n\")\n",
    "\n",
    "print(\"Distribuci√≥n original (conteo y %):\")\n",
    "display(resumen(y_train))\n",
    "\n",
    "print(\"Distribuci√≥n balanceada (conteo y %):\")\n",
    "display(resumen(y_train_under))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost SIN regularizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "xgb_base = Pipeline(steps=[\n",
    "    ('prep', preprocessing_pipeline),\n",
    "    ('clf', XGBClassifier(\n",
    "        n_estimators=300, max_depth=4, learning_rate=0.1,\n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        reg_lambda=0, reg_alpha=0,                # sin regularizaci√≥n\n",
    "        eval_metric=\"auc\", random_state=seed\n",
    "    ))\n",
    "])\n",
    "\n",
    "xgb_base.fit(X_train_under, y_train_under)\n",
    "metrics_xgb_base = evaluar_modelo(xgb_base, X_train_under, y_train_under, X_test, y_test, \"XGB ‚Äì Base (sin reg)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost con Ridge (L2: reg_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_ridge = Pipeline(steps=[\n",
    "    ('prep', preprocessing_pipeline),\n",
    "    ('clf', XGBClassifier(\n",
    "        n_estimators=300, max_depth=4, learning_rate=0.1,\n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        reg_lambda=10, reg_alpha=0,               # Ridge\n",
    "        eval_metric=\"auc\", random_state=seed\n",
    "    ))\n",
    "])\n",
    "\n",
    "xgb_ridge.fit(X_train_under, y_train_under)\n",
    "metrics_xgb_ridge = evaluar_modelo(xgb_ridge, X_train_under, y_train_under, X_test, y_test, \"XGB ‚Äì Ridge (L2)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost con Lasso (L1: reg_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_lasso = Pipeline(steps=[\n",
    "    ('prep', preprocessing_pipeline),\n",
    "    ('clf', XGBClassifier(\n",
    "        n_estimators=300, max_depth=4, learning_rate=0.1,\n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        reg_lambda=0, reg_alpha=10,               # Lasso\n",
    "        eval_metric=\"auc\", random_state=seed\n",
    "    ))\n",
    "])\n",
    "\n",
    "xgb_lasso.fit(X_train_under, y_train_under)\n",
    "metrics_xgb_lasso = evaluar_modelo(xgb_lasso, X_train_under, y_train_under, X_test, y_test, \"XGB ‚Äì Lasso (L1)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost con Elastic Net (L1 + L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_elastic = Pipeline(steps=[\n",
    "    ('prep', preprocessing_pipeline),\n",
    "    ('clf', XGBClassifier(\n",
    "        n_estimators=300, max_depth=4, learning_rate=0.1,\n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        reg_lambda=5, reg_alpha=5,                # Elastic Net\n",
    "        eval_metric=\"auc\", random_state=seed\n",
    "    ))\n",
    "])\n",
    "\n",
    "xgb_elastic.fit(X_train_under, y_train_under)\n",
    "metrics_xgb_elastic = evaluar_modelo(xgb_elastic, X_train_under, y_train_under, X_test, y_test, \"XGB ‚Äì Elastic Net\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaci√≥n de m√©tricas (Accuracy, Recall, Precision, AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_xgb = pd.DataFrame([\n",
    "    {\"Modelo\": \"XGB Base\",        **metrics_xgb_base},\n",
    "    {\"Modelo\": \"XGB Ridge (L2)\",  **metrics_xgb_ridge},\n",
    "    {\"Modelo\": \"XGB Lasso (L1)\",  **metrics_xgb_lasso},\n",
    "    {\"Modelo\": \"XGB Elastic\",     **metrics_xgb_elastic},\n",
    "])\n",
    "display(df_xgb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curvas ROC comparativas (con AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "for nombre, modelo in [\n",
    "    (\"XGB Base\", xgb_base),\n",
    "    (\"XGB Ridge (L2)\", xgb_ridge),\n",
    "    (\"XGB Lasso (L1)\", xgb_lasso),\n",
    "    (\"XGB Elastic\", xgb_elastic),\n",
    "]:\n",
    "    y_proba = modelo.predict_proba(X_test)[:,1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f\"{nombre} (AUC={auc:.3f})\")\n",
    "\n",
    "plt.plot([0,1],[0,1],'--',color='gray')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate (Recall)\")\n",
    "plt.title(\"Curvas ROC ‚Äì XGBoost (Base vs Regularizaciones)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "\n",
    "for nombre, modelo in [\n",
    "    (\"XGB Base\", xgb_base),\n",
    "    (\"XGB Ridge (L2)\", xgb_ridge),\n",
    "    (\"XGB Lasso (L1)\", xgb_lasso),\n",
    "    (\"XGB Elastic\", xgb_elastic),\n",
    "]:\n",
    "    y_proba = modelo.predict_proba(X_test)[:, 1]\n",
    "    prec, rec, _ = precision_recall_curve(y_test, y_proba)\n",
    "    ap = average_precision_score(y_test, y_proba)\n",
    "    plt.plot(rec, prec, lw=2, label=f\"{nombre} (AP={ap:.3f})\")\n",
    "\n",
    "# l√≠nea base: proporci√≥n positiva en test\n",
    "pos_rate = (y_test == 1).mean()\n",
    "plt.hlines(pos_rate, 0, 1, linestyles='--', colors='gray', label=f\"Base rate = {pos_rate:.2f}\")\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Curvas Precision‚ÄìRecall ‚Äì XGBoost (Base vs Regularizaciones)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xlim(0, 1); plt.ylim(0, 1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegir mejores modelos por AUC y por Recall (test)\n",
    "candidatos = [\n",
    "    (\"XGB Base\",    xgb_base,    metrics_xgb_base),\n",
    "    (\"XGB Ridge\",   xgb_ridge,   metrics_xgb_ridge),\n",
    "    (\"XGB Lasso\",   xgb_lasso,   metrics_xgb_lasso),\n",
    "    (\"XGB Elastic\", xgb_elastic, metrics_xgb_elastic),\n",
    "]\n",
    "\n",
    "# Mejor por AUC\n",
    "mejor_auc_nombre, mejor_auc_modelo, mejor_auc_score = max(\n",
    "    ((n, m, met[\"roc_auc\"]) for n, m, met in candidatos),\n",
    "    key=lambda t: t[2]\n",
    ")\n",
    "\n",
    "# Mejor por Recall (test)\n",
    "mejor_rec_nombre, mejor_rec_modelo, mejor_rec_score = max(\n",
    "    ((n, m, met[\"test_recall\"]) for n, m, met in candidatos),\n",
    "    key=lambda t: t[2]\n",
    ")\n",
    "\n",
    "print(f\">>> Mejor por AUC     : {mejor_auc_nombre}  | AUC={mejor_auc_score:.4f}\")\n",
    "print(f\">>> Mejor por Recall  : {mejor_rec_nombre} | Recall={mejor_rec_score:.4f}\")\n",
    "\n",
    "# (Opcional) hiperpar√°metros internos del clasificador ganador en cada criterio\n",
    "print(\"\\nHiperpar√°metros ‚Äì ganador por AUC:\")\n",
    "print(mejor_auc_modelo.named_steps['clf'].get_params())\n",
    "\n",
    "print(\"\\nHiperpar√°metros ‚Äì ganador por Recall:\")\n",
    "print(mejor_rec_modelo.named_steps['clf'].get_params())\n",
    "\n",
    "# (Opcional) dejar variables de salida para usar despu√©s\n",
    "best_by_auc     = {\"nombre\": mejor_auc_nombre, \"modelo\": mejor_auc_modelo, \"score\": mejor_auc_score}\n",
    "best_by_recall  = {\"nombre\": mejor_rec_nombre, \"modelo\": mejor_rec_modelo, \"score\": mejor_rec_score}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C√≥digo completo XGBOOST con Undersampling y Regularizaci√≥n L1, cross_validation y Optimizaci√≥n del umbral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# 1Ô∏è‚É£ BALANCEO DE CLASES (UNDERSAMPLING)\n",
    "# ===============================================\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Se iguala la cantidad de clases para evitar sesgo hacia la clase mayoritaria\n",
    "under = RandomUnderSampler(sampling_strategy=1.0, random_state=seed)\n",
    "X_train_under, y_train_under = under.fit_resample(X_train, y_train)\n",
    "\n",
    "# Mostrar tama√±os y proporciones\n",
    "print(\"UNDER aplicado correctamente ‚úÖ\")\n",
    "print(f\"Tama√±o original: {X_train.shape[0]} filas\")\n",
    "print(f\"Tama√±o balanceado: {X_train_under.shape[0]} filas\\n\")\n",
    "\n",
    "print(\"Distribuci√≥n original:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nDistribuci√≥n balanceada:\")\n",
    "print(y_train_under.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# 2Ô∏è‚É£ MODELO XGBOOST CON REGULARIZACI√ìN LASSO (L1)\n",
    "# ===============================================\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Regularizaci√≥n L1 se controla con reg_alpha > 0\n",
    "xgb_lasso = Pipeline(steps=[\n",
    "    ('prep', preprocessing_pipeline),\n",
    "    ('clf', XGBClassifier(\n",
    "        n_estimators=300, max_depth=4, learning_rate=0.1,\n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        reg_lambda=0, reg_alpha=10,               # Lasso (L1)\n",
    "        eval_metric=\"auc\", random_state=seed\n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"Modelo XGBoost con regularizaci√≥n L1 configurado ‚úÖ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# 3Ô∏è‚É£ VALIDACI√ìN CRUZADA (STRATIFIED K-FOLD)\n",
    "# ===============================================\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, average_precision_score\n",
    "import numpy as np\n",
    "\n",
    "# Se define validaci√≥n cruzada estratificada (mantiene proporciones de clases)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "# Vector para guardar probabilidades OOF (out-of-fold)\n",
    "oof_proba = np.zeros(len(y_train_under), dtype=float)\n",
    "\n",
    "for tr_idx, va_idx in cv.split(X_train_under, y_train_under):\n",
    "    xtr, xva = X_train_under.iloc[tr_idx], X_train_under.iloc[va_idx]\n",
    "    ytr, yva = y_train_under.iloc[tr_idx], y_train_under.iloc[va_idx]\n",
    "    \n",
    "    xgb_lasso.fit(xtr, ytr)\n",
    "    oof_proba[va_idx] = xgb_lasso.predict_proba(xva)[:, 1]\n",
    "\n",
    "# Calcular AUC promedio de la validaci√≥n cruzada\n",
    "auc_cv = roc_auc_score(y_train_under, oof_proba)\n",
    "ap_cv  = average_precision_score(y_train_under, oof_proba)\n",
    "\n",
    "print(f\"AUC promedio CV: {auc_cv:.3f}\")\n",
    "print(f\"Average Precision (PR-AUC) CV: {ap_cv:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# 4Ô∏è‚É£ OPTIMIZACI√ìN DEL UMBRAL (THRESHOLD)\n",
    "# ===============================================\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Calculamos curva Precision-Recall\n",
    "prec, rec, thr = precision_recall_curve(y_train_under, oof_proba)\n",
    "f1 = 2 * prec * rec / (prec + rec + 1e-12)\n",
    "thr_candidates = np.r_[thr, 1.0]  # Alinear longitudes\n",
    "\n",
    "# Seleccionamos el umbral que maximiza el F1\n",
    "idx_opt = np.nanargmax(f1)\n",
    "thr_opt = float(thr_candidates[idx_opt])\n",
    "\n",
    "print(f\"Umbral √≥ptimo seleccionado: {thr_opt:.3f}\")\n",
    "print(f\"F1 √≥ptimo: {f1[idx_opt]:.3f} | Precisi√≥n: {prec[idx_opt]:.3f} | Recall: {rec[idx_opt]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# 5Ô∏è‚É£ REENTRENAMIENTO Y EVALUACI√ìN FINAL EN TEST\n",
    "# ===============================================\n",
    "\n",
    "# Entrenamos el modelo con todos los datos balanceados\n",
    "xgb_lasso.fit(X_train_under, y_train_under)\n",
    "\n",
    "# Calculamos probabilidades y predicciones en Test con el umbral √≥ptimo\n",
    "proba_test = xgb_lasso.predict_proba(X_test)[:, 1]\n",
    "pred_test  = (proba_test >= thr_opt).astype(int)\n",
    "\n",
    "# Evaluamos con la funci√≥n definida previamente\n",
    "metrics_xgb_lasso_opt = evaluar_modelo(xgb_lasso, X_train_under, y_train_under, X_test, y_test, nombre=\"XGBoost Lasso (L1) ‚Äì Threshold √ìptimo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "defi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
