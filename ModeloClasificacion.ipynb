{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-image: url('https://i.pinimg.com/1200x/45/3a/06/453a06bdc2b2d27d8329857061537124.jpg'); \n",
    "            background-size: cover; \n",
    "            background-position: center; \n",
    "            padding: 30px; \n",
    "            text-align: center; \n",
    "            border-radius: 8px;\">\n",
    "    <h1 style=\"color: white; \n",
    "               font-size: 28px; \n",
    "               font-weight: bold; \n",
    "               text-shadow: 2px 2px 4px rgba(0,0,0,0.8), \n",
    "                            -1px -1px 2px rgba(0,0,0,0.8);\n",
    "               margin: 0;\n",
    "               font-family: 'Arial', sans-serif;\">\n",
    "        PROYECTO: MODELO DE RIESGO\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- María José Castillo Silva\n",
    "- Juan David Bocanegra Vargas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container{ width:98% }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Permite ajustar la anchura de la parte útil de la libreta (reduce los márgenes) y omitir warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.display import HTML\n",
    "display(HTML(\"<style>.container{ width:98% }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Problema a Analizar\n",
    "\n",
    "# ¿Cuál es la probabilidad de riesgo de default asociada a cada cliente, dadas sus diferentes características?.\n",
    "\n",
    "La principal fuente de datos es Datacredito Experian, quienes envían información de los clientes actuales de la Entidad, incluyendo las siguientes variables: “Acierta Advance”, score de crédito del sector financiero, saldos, estados de productos crediticios y también información demografica como edad, sexo, entre otras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Impacto del Problema\n",
    "\n",
    "Actualmente en las áreas de riesgo de crédito en el sector bancario, se definen constantemente políticas que permiten soportar la toma de decisiones en la originación  de productos, que en la medida de lo posible, estén enmarcadas en la agilidad y precisión de la respuesta a clientes, y vayan en línea con el apetito financiero propuesto por la Junta Directiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Datos, primer análisis exploratorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalación de Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install eli5\n",
    "#!pip install pandas\n",
    "#!pip install numpy\n",
    "#!pip install seaborn\n",
    "#!pip install yellowbrick\n",
    "#!pip install xgboost\n",
    "#!pip install shap\n",
    "#!pip install matplotlib\n",
    "#!pip install scikit-learn\n",
    "#!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U scikit-learn==1.5.2 imbalanced-learn==0.12.3 yellowbrick==1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Núcleo científico / utilidades\n",
    "# ===============================\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===============================\n",
    "# Modelado y validación (scikit-learn)\n",
    "# ===============================\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, StratifiedKFold, RandomizedSearchCV, cross_val_score\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score, roc_curve, precision_recall_curve,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "\n",
    "# ===============================\n",
    "# Desbalanceo de clases (imbalanced-learn)\n",
    "# ===============================\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# ===============================\n",
    "# Gradient Boosting (XGBoost)\n",
    "# ===============================\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# ===============================\n",
    "# Estadística (SciPy y Statsmodels)\n",
    "# ===============================\n",
    "from scipy import stats\n",
    "from scipy.stats import shapiro, normaltest, ttest_ind, mannwhitneyu\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor  # VIF\n",
    "\n",
    "# ===============================\n",
    "# Otros apoyos\n",
    "# ===============================\n",
    "from collections import Counter\n",
    "\n",
    "# ===============================\n",
    "# Opcionales de interpretación/visual\n",
    "# ===============================\n",
    "import shap\n",
    "from yellowbrick.classifier import ROCAUC, ConfusionMatrix, ClassificationReport\n",
    "import eli5\n",
    "\n",
    "# ===============================\n",
    "# Estilo de gráficos\n",
    "# ===============================\n",
    "plt.style.use(\"ggplot\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('base_modelo_40k.csv', sep=',')\n",
    "datos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datos.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Inicialmente se contemplaron 40 variables en estudio, mixtas entre categóricas y numéricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza y Armonización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONVERSIÓN TIPOS DE FORMATO\n",
    "datos['CRED_REESTRUCTURADO']=datos['CRED_REESTRUCTURADO'].astype('object')\n",
    "datos['TIENE_HIPOTECA']=datos['TIENE_HIPOTECA'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Conteo valores nulos\n",
    "datos.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Por criterio experto, se consideran no necesarias las variables asociadas a la identificación del cliente, como el tipo de Id, el número de identificación y la fecha de evaluación; también se elimina la variable \"Acierta_plus\" ya que existe la variable \"Advance\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ELIMINAR COLUMNAS NO NECESARIAS\n",
    "datos=datos.drop(labels='ID',axis=1)\n",
    "datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dimensión base de datos\n",
    "print(datos.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis Exploratorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La Variable de interés es la variable llamada VAR_DEP, que es 1 si el cliente tuvo una mora mayor a 90 días en los doce meses siguientes al desembolso del credito y 0 si ha estado al día."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Proporción de clientes en Mora\n",
    "datos.groupby('CLIENTE_MORA').size()/datos['CLIENTE_MORA'].count()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La base con 54.759 clientes, contiene un 7.08% de clientes en mora y un 92.92% de clientes al día"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separación de Bases\n",
    "datos_0 = datos[datos['CLIENTE_MORA'] == 0]\n",
    "datos_1 = datos[datos['CLIENTE_MORA'] == 1]\n",
    "\n",
    "#Función de densidad \n",
    "datos_0.SCORE_DATACREDITO.plot.density(color='green',label='Clientes Al día') \n",
    "datos_1.SCORE_DATACREDITO.plot.density(color='red',label='Clientes en Mora')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Score Datacredito\")\n",
    "plt.ylabel('Probabilidad numérica')\n",
    "plt.title('Score Datacredito Clientes al día y en mora')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se evidencia que los clientes que han tenido una mora de 90 días o más en los 12 ultimos meses tienen un Score Advance (cálculo por datacredito) menor a los clientes que han estado al día. También se resalta que, la mayoría de clientes en mora tienen un Score Advance entre 500 a 850, en cambio los clientes que han estado al día tienen un score adnvance entre 650 a 950."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruebas estadísticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de normalidad Shapiro-Wilk\n",
    "print(\"Prueba Shapiro-Wilk Población al día:\",shapiro(datos_0['SCORE_DATACREDITO']))\n",
    "print(\"Prueba Shapiro-Wilk Población en mora:\",shapiro(datos_1['SCORE_DATACREDITO']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diferencia de medias\n",
    "def dif_medias (df1, df2, alfa):\n",
    "    stat, p = ttest_ind(df1,df2, equal_var = False)\n",
    "    print(\"Statistic=%.3f, p=%.3f\" % (stat,p))\n",
    "\n",
    "dif_medias (datos_0['SCORE_DATACREDITO'], datos_1['SCORE_DATACREDITO'], 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba no parametrcia Mann-Whitney para comparar la variable ADVANCE en los dos grupos\n",
    "stat, p = mannwhitneyu(datos_0['SCORE_DATACREDITO'], datos_1['SCORE_DATACREDITO'], alternative='two-sided')\n",
    "\n",
    "print(\"Mann-Whitney U Test\")\n",
    "print(f\"Estadístico U = {stat:.3f}, p-valor = {p:.3e}\")\n",
    "\n",
    "# Interpretación rápida\n",
    "alpha = 0.05\n",
    "if p < alpha:\n",
    "    print(\"👉 Se rechaza H0: Las distribuciones de ADVANCE en los dos grupos son diferentes.\")\n",
    "else:\n",
    "    print(\"👉 No se rechaza H0: No hay evidencia de diferencia significativa entre los grupos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Existe evidencia estadísticamente significativa para afirmar que las medias de la variable ADVANCE en los dos grupos comparados (datos_0 y datos_1) son diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_0.ANT_SF.plot.density(color='green',label='Clientes Al día') \n",
    "datos_1.ANT_SF.plot.density(color='red',label='Clientes en Mora')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Antigüedad Financiera\")\n",
    "plt.ylabel('Probabilidad numérica')\n",
    "plt.title('Antigüedad Financiera de Clientes al día y en mora')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se evidencia como lo clientes que estan al día tienden  a tener mayor antiguedad en el sector financiero a comparación de los cliente en mora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba K-S\n",
    "stats.ks_2samp(datos_0['ANT_SF'], datos_1['ANT_SF'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👉 Los clientes al día tienden a tener una mayor antigüedad en el sistema financiero que los clientes en mora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_0.EDAD.plot.density(color='green',label='Clientes Al día') \n",
    "datos_1.EDAD.plot.density(color='red',label='Clientes en Mora')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Edad\")\n",
    "plt.ylabel('Probabilidad numérica')\n",
    "plt.title('Edad Clientes al día y en mora')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Los clientes en mora tienden a concentrarse en edades entre los 30 a los 40 años, en cambio los clientes al día tienden a ser de mayor edad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(datos['SEXO'], datos['CLIENTE_MORA'], normalize='index')*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se evidencia que las mujeres pagan mejor que los hombres, dado que el porcentaje de incumplimiento de las mujeres es 6.7% en cambio de los hombres es de 7.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_0.INGRESO.plot.density(color='green',label='Clientes Al día') \n",
    "datos_1.INGRESO.plot.density(color='red',label='Clientes en Mora')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Ingresos\")\n",
    "plt.ylabel('Probabilidad numérica')\n",
    "plt.title('Ingresos de Clientes al día y en mora')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se evidencia que no existen diferencias de ingreso respecto al incumplimiento de pago de los clientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datos_0.INGRESO.plot.density(color='green',label='Clientes Al día') \n",
    "datos_1.INGRESO.plot.density(color='red',label='Clientes en Mora')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Ingresos\")\n",
    "plt.ylabel('Probabilidad numérica')\n",
    "plt.title('Ingresos de Clientes al día y en mora')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlación compacta con encabezados verticales sin superposición\n",
    "corr = datos.select_dtypes(include='number').corr().round(2)\n",
    "\n",
    "display(\n",
    "    corr.style\n",
    "        .format(\"{:.2f}\")\n",
    "        .background_gradient(cmap=\"BrBG\")\n",
    "        # fuente y padding pequeños en todo\n",
    "        .set_properties(**{\"font-size\":\"8pt\", \"padding\":\"2px\"})\n",
    "        # estilos específicos de encabezados\n",
    "        .set_table_styles([\n",
    "            # columnas: vertical, ancho fijo pequeño, sin quiebre ni solape\n",
    "            {\"selector\":\"th.col_heading\",\n",
    "             \"props\":[\n",
    "                 (\"writing-mode\",\"vertical-rl\"),\n",
    "                 (\"text-orientation\",\"mixed\"),\n",
    "                 (\"width\",\"24px\"), (\"min-width\",\"24px\"), (\"max-width\",\"24px\"),\n",
    "                 (\"height\",\"140px\"),\n",
    "                 (\"white-space\",\"nowrap\"),\n",
    "                 (\"overflow\",\"hidden\"),\n",
    "                 (\"text-overflow\",\"clip\"),\n",
    "                 (\"font-size\",\"7pt\"),\n",
    "                 (\"padding\",\"6px 2px\")\n",
    "             ]},\n",
    "            # filas: fuente pequeña\n",
    "            {\"selector\":\"th.row_heading\",\n",
    "             \"props\":[(\"font-size\",\"7pt\"), (\"white-space\",\"nowrap\")]}\n",
    "        ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En la matriz de correlación se evidencia que las variables que más estan relacionadas con la variable de incumplimiento de pago es el score Advance generado por Datacredito y en segunda medida variables como los saldos de los creditos, los estados de mora y la antiguedad en el sector financiero. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminación de variables VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Solo numéricas y limpieza mínima\n",
    "num = datos.select_dtypes(include='number').copy()\n",
    "num = num.dropna(axis=1, how='all')                 # quita columnas totalmente vacías\n",
    "num = num.loc[:, num.nunique()>1]                   # quita columnas con varianza 0\n",
    "num = num.fillna(num.median(numeric_only=True))     # imputación simple (si hay NA)\n",
    "\n",
    "# 2) Matriz para VIF (no necesita estandarizar)\n",
    "X = sm.add_constant(num, has_constant='add')\n",
    "\n",
    "# 3) Calcular VIF (omitimos la constante en el resultado)\n",
    "vif_vals = [variance_inflation_factor(X.values, i) for i in range(1, X.shape[1])]\n",
    "vifs = (pd.DataFrame({'Variable': num.columns, 'VIF': vif_vals})\n",
    "          .replace([np.inf, -np.inf], np.nan)\n",
    "          .sort_values('VIF', ascending=False)\n",
    "          .reset_index(drop=True))\n",
    "\n",
    "# 4) Mostrar\n",
    "display(vifs.style.format({'VIF':'{:.2f}'}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# X e y\n",
    "X = datos.drop(columns='CLIENTE_MORA')\n",
    "y = datos['CLIENTE_MORA']\n",
    "\n",
    "# Detecta columnas\n",
    "cat_cols = X.select_dtypes(include=['object','category']).columns.tolist()\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# OneHotEncoder compatible (1.2-1.5+)\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)  # sklearn ≥1.2\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)         # sklearn <1.2\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    ('num', RobustScaler(), num_cols),\n",
    "    ('cat', ohe, cat_cols)\n",
    "], remainder='drop')\n",
    "\n",
    "X_pre = preprocess.fit_transform(X)\n",
    "print(f\"Shape original: {X.shape} → transformado: {X_pre.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partición Train Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 2025\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=seed, stratify=y, shuffle=True\n",
    ")\n",
    "\n",
    "# asegurar que preprocessing_pipeline exista\n",
    "try:\n",
    "    preprocessing_pipeline\n",
    "except NameError:\n",
    "    preprocessing_pipeline = preprocess\n",
    "\n",
    "print(f\"Split OK → X_train: {X_train.shape}, X_test: {X_test.shape}, seed={seed}\")\n",
    "print(\"preprocessing_pipeline definido ✅\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelo(best_model, X_train, y_train, X_test, y_test, nombre=\"Modelo\", pos_label=1):\n",
    "    \"\"\"Imprime métricas y devuelve un dict con resultados clave.\"\"\"\n",
    "    # Predicciones duras\n",
    "    pred_train = best_model.predict(X_train)\n",
    "    pred_test  = best_model.predict(X_test)\n",
    "\n",
    "    # Probabilidades para AUC y PR-AUC\n",
    "    if hasattr(best_model, \"predict_proba\"):\n",
    "        proba_test = best_model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        proba_test = best_model.decision_function(X_test)\n",
    "\n",
    "    # Métricas\n",
    "    train_acc    = accuracy_score(y_train, pred_train)\n",
    "    test_acc     = accuracy_score(y_test,  pred_test)\n",
    "    train_recall = recall_score(y_train, pred_train, pos_label=pos_label, zero_division=0)\n",
    "    test_recall  = recall_score(y_test,  pred_test,  pos_label=pos_label, zero_division=0)\n",
    "    train_prec   = precision_score(y_train, pred_train, pos_label=pos_label, zero_division=0)\n",
    "    test_prec    = precision_score(y_test,  pred_test,  pos_label=pos_label, zero_division=0)\n",
    "    roc_test     = roc_auc_score(y_test, proba_test)\n",
    "    pr_test      = average_precision_score(y_test, proba_test)\n",
    "\n",
    "    # Reporte\n",
    "    print(f\"=== {nombre} ===\")\n",
    "    print('Train Accuracy  : ', train_acc)\n",
    "    print('Test  Accuracy  : ', test_acc)\n",
    "    print('Train Recall    : ', train_recall)\n",
    "    print('Test  Recall    : ', test_recall)\n",
    "    print('Train Precision : ', train_prec)\n",
    "    print('Test  Precision : ', test_prec)\n",
    "    print('ROC AUC (test)  : ', roc_test)\n",
    "\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(confusion_matrix(y_test, pred_test))\n",
    "\n",
    "    print('\\nClassification Report:')\n",
    "    print(classification_report(y_test, pred_test, zero_division=0))\n",
    "\n",
    "    return {\n",
    "        \"train_acc\":    train_acc,\n",
    "        \"test_acc\":     test_acc,\n",
    "        \"train_recall\": train_recall,\n",
    "        \"test_recall\":  test_recall,\n",
    "        \"train_prec\":   train_prec,\n",
    "        \"test_prec\":    test_prec,\n",
    "        \"roc_auc\":      roc_test\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definicion Hiperparámetros y CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "seed = globals().get('seed', 42)\n",
    "\n",
    "param_grid = {\n",
    "    \"model\": [DecisionTreeClassifier(random_state=seed)],\n",
    "    \"model__criterion\": [\"gini\", \"entropy\"],\n",
    "    \"model__splitter\": [\"best\", \"random\"],\n",
    "    \"model__max_leaf_nodes\": [128, 256, 512, 1024],\n",
    "    \"model__max_depth\": list(map(int, np.linspace(4, 16, 32)))\n",
    "}\n",
    "\n",
    "scoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=seed, shuffle=True)\n",
    "n_iter = 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline base (sin balanceo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not any(v not in globals() for v in [\"X_train\",\"X_test\",\"y_train\",\"y_test\",\"preprocessing_pipeline\"]):\n",
    "    full_pipeline_steps = [\n",
    "        ('preprocessing_pipeline', preprocessing_pipeline),\n",
    "        ('model', DecisionTreeClassifier(random_state=seed))\n",
    "    ]\n",
    "    full_pipeline = Pipeline(steps=full_pipeline_steps)\n",
    "\n",
    "    grid_base = RandomizedSearchCV(\n",
    "        estimator=full_pipeline,\n",
    "        param_distributions=param_grid,\n",
    "        cv=kfold,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "        n_iter=n_iter,\n",
    "        refit=\"AUC\",\n",
    "        random_state=seed\n",
    "    )\n",
    "    best_model_base = grid_base.fit(X_train, y_train)\n",
    "    print(\">> Mejor AUC (CV) – Base:\", best_model_base.best_score_)\n",
    "\n",
    "    # === Métricas adicionales: Recall y AUC en train y test ===\n",
    "    est = best_model_base.best_estimator_\n",
    "\n",
    "    # Predicciones duras\n",
    "    pred_train = est.predict(X_train)\n",
    "    pred_test  = est.predict(X_test)\n",
    "\n",
    "    # Scores probabilísticos para AUC\n",
    "    if hasattr(est, \"predict_proba\"):\n",
    "        score_train = est.predict_proba(X_train)[:, 1]\n",
    "        score_test  = est.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        score_train = est.decision_function(X_train)\n",
    "        score_test  = est.decision_function(X_test)\n",
    "\n",
    "else:\n",
    "    print(\"⛔ Define X_train/X_test/y_train/y_test/preprocessing_pipeline antes de ejecutar esta celda.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling dentro del CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not any(v not in globals() for v in [\"X_train\",\"X_test\",\"y_train\",\"y_test\",\"preprocessing_pipeline\"]):\n",
    "    undersampler = RandomUnderSampler(random_state=seed)\n",
    "\n",
    "    pipe_under = ImbPipeline(steps=[\n",
    "        ('preprocessing_pipeline', preprocessing_pipeline),\n",
    "        ('sampler', undersampler),\n",
    "        ('model', DecisionTreeClassifier(random_state=seed))\n",
    "    ])\n",
    "\n",
    "    grid_under = RandomizedSearchCV(\n",
    "        estimator=pipe_under,\n",
    "        param_distributions=param_grid,\n",
    "        cv=kfold,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "        n_iter=n_iter,\n",
    "        refit=\"AUC\",\n",
    "        random_state=seed\n",
    "    )\n",
    "\n",
    "    best_model_under = grid_under.fit(X_train, y_train)\n",
    "    print(\">> Mejor AUC (CV) – Undersampling:\", best_model_under.best_score_)\n",
    "else:\n",
    "    print(\"⛔ Define X_train/X_test/y_train/y_test/preprocessing_pipeline antes de ejecutar esta celda.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling dentro del CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not any(v not in globals() for v in [\"X_train\",\"X_test\",\"y_train\",\"y_test\",\"preprocessing_pipeline\"]):\n",
    "    oversampler = RandomOverSampler(random_state=seed)\n",
    "\n",
    "    pipe_over = ImbPipeline(steps=[\n",
    "        ('preprocessing_pipeline', preprocessing_pipeline),\n",
    "        ('sampler', oversampler),\n",
    "        ('model', DecisionTreeClassifier(random_state=seed))\n",
    "    ])\n",
    "\n",
    "    grid_over = RandomizedSearchCV(\n",
    "        estimator=pipe_over,\n",
    "        param_distributions=param_grid,\n",
    "        cv=kfold,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "        n_iter=n_iter,\n",
    "        refit=\"AUC\",\n",
    "        random_state=seed\n",
    "    )\n",
    "\n",
    "    best_model_over = grid_over.fit(X_train, y_train)\n",
    "    print(\">> Mejor AUC (CV) – Oversampling:\", best_model_over.best_score_)\n",
    "else:\n",
    "    print(\"⛔ Define X_train/X_test/y_train/y_test/preprocessing_pipeline antes de ejecutar esta celda.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE dentro del CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import recall_score, roc_auc_score  # por si faltan\n",
    "\n",
    "if not any(v not in globals() for v in [\"X_train\",\"X_test\",\"y_train\",\"y_test\",\"preprocessing_pipeline\"]):\n",
    "    smote = SMOTE(random_state=seed, k_neighbors=5)  # puedes tunear k_neighbors\n",
    "\n",
    "    pipe_smote = ImbPipeline(steps=[\n",
    "        ('preprocessing_pipeline', preprocessing_pipeline),\n",
    "        ('sampler', smote),\n",
    "        ('model', DecisionTreeClassifier(random_state=seed))\n",
    "    ])\n",
    "\n",
    "    grid_smote = RandomizedSearchCV(\n",
    "        estimator=pipe_smote,\n",
    "        param_distributions=param_grid,\n",
    "        cv=kfold,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "        n_iter=n_iter,\n",
    "        refit=\"AUC\",\n",
    "        random_state=seed\n",
    "    )\n",
    "\n",
    "    best_model_smote = grid_smote.fit(X_train, y_train)\n",
    "    print(\">> Mejor AUC (CV) – SMOTE:\", best_model_smote.best_score_)\n",
    "\n",
    "    # Métricas rápidas (train/test) para Recall y AUC\n",
    "    est = best_model_smote.best_estimator_\n",
    "    pred_train = est.predict(X_train)\n",
    "    pred_test  = est.predict(X_test)\n",
    "\n",
    "    if hasattr(est, \"predict_proba\"):\n",
    "        score_train = est.predict_proba(X_train)[:, 1]\n",
    "        score_test  = est.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        score_train = est.decision_function(X_train)\n",
    "        score_test  = est.decision_function(X_test)\n",
    "\n",
    "    print(f\"Train Recall: {recall_score(y_train, pred_train, zero_division=0):.4f} | \"\n",
    "          f\"Train AUC: {roc_auc_score(y_train, score_train):.4f}\")\n",
    "    print(f\"Test  Recall: {recall_score(y_test,  pred_test,  zero_division=0):.4f} | \"\n",
    "          f\"Test  AUC:  {roc_auc_score(y_test,  score_test):.4f}\")\n",
    "else:\n",
    "    print(\"⛔ Define X_train/X_test/y_train/y_test/preprocessing_pipeline antes de ejecutar esta celda.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validaciones finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 10. Validaciones finales (incluye SMOTE si existe) =====\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, recall_score, roc_auc_score, average_precision_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "models_to_eval = []\n",
    "if 'best_model_base'  in globals(): models_to_eval.append((\"Árbol – Base (sin balanceo)\", best_model_base.best_estimator_))\n",
    "if 'best_model_under' in globals(): models_to_eval.append((\"Árbol – Undersampling\",        best_model_under.best_estimator_))\n",
    "if 'best_model_over'  in globals(): models_to_eval.append((\"Árbol – Oversampling\",         best_model_over.best_estimator_))\n",
    "if 'best_model_smote' in globals(): models_to_eval.append((\"Árbol – SMOTE\",                best_model_smote.best_estimator_))\n",
    "\n",
    "if models_to_eval:\n",
    "    metrics_map = {}\n",
    "    for nombre, est in models_to_eval:\n",
    "        metrics_map[nombre] = evaluar_modelo(est, X_train, y_train, X_test, y_test, nombre=nombre)\n",
    "\n",
    "    # (opcional) dejar variables sueltas como antes:\n",
    "    if 'best_model_base'  in globals(): metrics_base  = metrics_map[\"Árbol – Base (sin balanceo)\"]\n",
    "    if 'best_model_under' in globals(): metrics_under = metrics_map[\"Árbol – Undersampling\"]\n",
    "    if 'best_model_over'  in globals(): metrics_over  = metrics_map[\"Árbol – Oversampling\"]\n",
    "    if 'best_model_smote' in globals(): metrics_smote = metrics_map[\"Árbol – SMOTE\"]\n",
    "else:\n",
    "    print(\"⛔ No hay modelos para evaluar. Ejecuta primero Base/Under/Over/SMOTE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escoger el mejor modelo y extraer el árbol final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidatos = []\n",
    "\n",
    "if 'best_model_base'  in globals() and 'metrics_base'  in globals():\n",
    "    candidatos.append((\"base\",  best_model_base,  metrics_base[\"test_recall\"]))\n",
    "if 'best_model_under' in globals() and 'metrics_under' in globals():\n",
    "    candidatos.append((\"under\", best_model_under, metrics_under[\"test_recall\"]))\n",
    "if 'best_model_over'  in globals() and 'metrics_over'  in globals():\n",
    "    candidatos.append((\"over\",  best_model_over,  metrics_over[\"test_recall\"]))\n",
    "if 'best_model_smote' in globals() and 'metrics_smote' in globals():\n",
    "    candidatos.append((\"smote\", best_model_smote, metrics_smote[\"test_recall\"]))\n",
    "\n",
    "if candidatos:\n",
    "    mejor_nombre, best_model, best_rec = max(candidatos, key=lambda x: x[2])\n",
    "    print(f\"\\n>>> Mejor enfoque según Recall (test): {mejor_nombre.upper()} con Recall={best_rec:.4f}\")\n",
    "    dt_model = best_model.best_estimator_['model']\n",
    "    print(\"\\nHiperparámetros del árbol ganador:\\n\", dt_model.get_params())\n",
    "else:\n",
    "    print(\"⛔ No hay candidatos para comparar. Corre las celdas de entrenamiento/validación primero.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curvas ROC y Precision-Recall del modelo ganador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, ConfusionMatrixDisplay,\n",
    "    roc_curve, roc_auc_score,\n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "\n",
    "# === Modelo ganador: best_model_under ===\n",
    "best_est = best_model_under.best_estimator_\n",
    "\n",
    "# Probabilidades y predicciones en test\n",
    "y_proba = best_est.predict_proba(X_test)[:,1]\n",
    "y_pred  = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "# === Matriz de confusión ===\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(cm).plot(cmap=\"Blues\")\n",
    "plt.title(\"Matriz de confusión – Modelo UNDER (umbral 0.5)\")\n",
    "plt.show()\n",
    "\n",
    "# === Curva ROC ===\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"ROC (AUC={roc_auc:.3f})\", lw=2)\n",
    "plt.plot([0,1],[0,1],\"--\", color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate (Recall)\")\n",
    "plt.title(\"Curva ROC – Modelo UNDER\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# === Curva Precision–Recall ===\n",
    "prec, rec, _ = precision_recall_curve(y_test, y_proba)\n",
    "ap = average_precision_score(y_test, y_proba)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(rec, prec, label=f\"PR (AP={ap:.3f})\", lw=2, color=\"darkorange\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Curva Precision–Recall – Modelo UNDER\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modelo XGBOOST CON REGULARIZACION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanceo UNDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import pandas as pd\n",
    "\n",
    "under = RandomUnderSampler(sampling_strategy=1.0, random_state=seed)\n",
    "X_train_under, y_train_under = under.fit_resample(X_train, y_train)\n",
    "\n",
    "# Resúmenes\n",
    "def resumen(y):\n",
    "    c = y.value_counts().sort_index()\n",
    "    p = y.value_counts(normalize=True).sort_index().mul(100).round(2)\n",
    "    return pd.DataFrame({\"count\": c, \"pct%\": p})\n",
    "\n",
    "print(\"UNDER aplicado\")\n",
    "print(f\"Tamaño original   : {X_train.shape[0]} filas\")\n",
    "print(f\"Tamaño balanceado : {X_train_under.shape[0]} filas\\n\")\n",
    "\n",
    "print(\"Distribución original (conteo y %):\")\n",
    "display(resumen(y_train))\n",
    "\n",
    "print(\"Distribución balanceada (conteo y %):\")\n",
    "display(resumen(y_train_under))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost SIN regularización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "xgb_base = Pipeline(steps=[\n",
    "    ('prep', preprocessing_pipeline),\n",
    "    ('clf', XGBClassifier(\n",
    "        n_estimators=300, max_depth=4, learning_rate=0.1,\n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        reg_lambda=0, reg_alpha=0,                # sin regularización\n",
    "        eval_metric=\"auc\", random_state=seed\n",
    "    ))\n",
    "])\n",
    "\n",
    "xgb_base.fit(X_train_under, y_train_under)\n",
    "metrics_xgb_base = evaluar_modelo(xgb_base, X_train_under, y_train_under, X_test, y_test, \"XGB – Base (sin reg)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost con Ridge (L2: reg_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_ridge = Pipeline(steps=[\n",
    "    ('prep', preprocessing_pipeline),\n",
    "    ('clf', XGBClassifier(\n",
    "        n_estimators=300, max_depth=4, learning_rate=0.1,\n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        reg_lambda=10, reg_alpha=0,               # Ridge\n",
    "        eval_metric=\"auc\", random_state=seed\n",
    "    ))\n",
    "])\n",
    "\n",
    "xgb_ridge.fit(X_train_under, y_train_under)\n",
    "metrics_xgb_ridge = evaluar_modelo(xgb_ridge, X_train_under, y_train_under, X_test, y_test, \"XGB – Ridge (L2)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost con Lasso (L1: reg_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_lasso = Pipeline(steps=[\n",
    "    ('prep', preprocessing_pipeline),\n",
    "    ('clf', XGBClassifier(\n",
    "        n_estimators=300, max_depth=4, learning_rate=0.1,\n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        reg_lambda=0, reg_alpha=10,               # Lasso\n",
    "        eval_metric=\"auc\", random_state=seed\n",
    "    ))\n",
    "])\n",
    "\n",
    "xgb_lasso.fit(X_train_under, y_train_under)\n",
    "metrics_xgb_lasso = evaluar_modelo(xgb_lasso, X_train_under, y_train_under, X_test, y_test, \"XGB – Lasso (L1)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost con Elastic Net (L1 + L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_elastic = Pipeline(steps=[\n",
    "    ('prep', preprocessing_pipeline),\n",
    "    ('clf', XGBClassifier(\n",
    "        n_estimators=300, max_depth=4, learning_rate=0.1,\n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        reg_lambda=5, reg_alpha=5,                # Elastic Net\n",
    "        eval_metric=\"auc\", random_state=seed\n",
    "    ))\n",
    "])\n",
    "\n",
    "xgb_elastic.fit(X_train_under, y_train_under)\n",
    "metrics_xgb_elastic = evaluar_modelo(xgb_elastic, X_train_under, y_train_under, X_test, y_test, \"XGB – Elastic Net\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación de métricas (Accuracy, Recall, Precision, AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_xgb = pd.DataFrame([\n",
    "    {\"Modelo\": \"XGB Base\",        **metrics_xgb_base},\n",
    "    {\"Modelo\": \"XGB Ridge (L2)\",  **metrics_xgb_ridge},\n",
    "    {\"Modelo\": \"XGB Lasso (L1)\",  **metrics_xgb_lasso},\n",
    "    {\"Modelo\": \"XGB Elastic\",     **metrics_xgb_elastic},\n",
    "])\n",
    "display(df_xgb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curvas ROC comparativas (con AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "for nombre, modelo in [\n",
    "    (\"XGB Base\", xgb_base),\n",
    "    (\"XGB Ridge (L2)\", xgb_ridge),\n",
    "    (\"XGB Lasso (L1)\", xgb_lasso),\n",
    "    (\"XGB Elastic\", xgb_elastic),\n",
    "]:\n",
    "    y_proba = modelo.predict_proba(X_test)[:,1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f\"{nombre} (AUC={auc:.3f})\")\n",
    "\n",
    "plt.plot([0,1],[0,1],'--',color='gray')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate (Recall)\")\n",
    "plt.title(\"Curvas ROC – XGBoost (Base vs Regularizaciones)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "\n",
    "for nombre, modelo in [\n",
    "    (\"XGB Base\", xgb_base),\n",
    "    (\"XGB Ridge (L2)\", xgb_ridge),\n",
    "    (\"XGB Lasso (L1)\", xgb_lasso),\n",
    "    (\"XGB Elastic\", xgb_elastic),\n",
    "]:\n",
    "    y_proba = modelo.predict_proba(X_test)[:, 1]\n",
    "    prec, rec, _ = precision_recall_curve(y_test, y_proba)\n",
    "    ap = average_precision_score(y_test, y_proba)\n",
    "    plt.plot(rec, prec, lw=2, label=f\"{nombre} (AP={ap:.3f})\")\n",
    "\n",
    "# línea base: proporción positiva en test\n",
    "pos_rate = (y_test == 1).mean()\n",
    "plt.hlines(pos_rate, 0, 1, linestyles='--', colors='gray', label=f\"Base rate = {pos_rate:.2f}\")\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Curvas Precision–Recall – XGBoost (Base vs Regularizaciones)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xlim(0, 1); plt.ylim(0, 1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegir mejores modelos por AUC y por Recall (test)\n",
    "candidatos = [\n",
    "    (\"XGB Base\",    xgb_base,    metrics_xgb_base),\n",
    "    (\"XGB Ridge\",   xgb_ridge,   metrics_xgb_ridge),\n",
    "    (\"XGB Lasso\",   xgb_lasso,   metrics_xgb_lasso),\n",
    "    (\"XGB Elastic\", xgb_elastic, metrics_xgb_elastic),\n",
    "]\n",
    "\n",
    "# Mejor por AUC\n",
    "mejor_auc_nombre, mejor_auc_modelo, mejor_auc_score = max(\n",
    "    ((n, m, met[\"roc_auc\"]) for n, m, met in candidatos),\n",
    "    key=lambda t: t[2]\n",
    ")\n",
    "\n",
    "# Mejor por Recall (test)\n",
    "mejor_rec_nombre, mejor_rec_modelo, mejor_rec_score = max(\n",
    "    ((n, m, met[\"test_recall\"]) for n, m, met in candidatos),\n",
    "    key=lambda t: t[2]\n",
    ")\n",
    "\n",
    "print(f\">>> Mejor por AUC     : {mejor_auc_nombre}  | AUC={mejor_auc_score:.4f}\")\n",
    "print(f\">>> Mejor por Recall  : {mejor_rec_nombre} | Recall={mejor_rec_score:.4f}\")\n",
    "\n",
    "# (Opcional) hiperparámetros internos del clasificador ganador en cada criterio\n",
    "print(\"\\nHiperparámetros – ganador por AUC:\")\n",
    "print(mejor_auc_modelo.named_steps['clf'].get_params())\n",
    "\n",
    "print(\"\\nHiperparámetros – ganador por Recall:\")\n",
    "print(mejor_rec_modelo.named_steps['clf'].get_params())\n",
    "\n",
    "# (Opcional) dejar variables de salida para usar después\n",
    "best_by_auc     = {\"nombre\": mejor_auc_nombre, \"modelo\": mejor_auc_modelo, \"score\": mejor_auc_score}\n",
    "best_by_recall  = {\"nombre\": mejor_rec_nombre, \"modelo\": mejor_rec_modelo, \"score\": mejor_rec_score}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código completo XGBOOST con Undersampling y Regularización L1, cross_validation y Optimización del umbral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# 1️⃣ BALANCEO DE CLASES (UNDERSAMPLING)\n",
    "# ===============================================\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Se iguala la cantidad de clases para evitar sesgo hacia la clase mayoritaria\n",
    "under = RandomUnderSampler(sampling_strategy=1.0, random_state=seed)\n",
    "X_train_under, y_train_under = under.fit_resample(X_train, y_train)\n",
    "\n",
    "# Mostrar tamaños y proporciones\n",
    "print(\"UNDER aplicado correctamente ✅\")\n",
    "print(f\"Tamaño original: {X_train.shape[0]} filas\")\n",
    "print(f\"Tamaño balanceado: {X_train_under.shape[0]} filas\\n\")\n",
    "\n",
    "print(\"Distribución original:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nDistribución balanceada:\")\n",
    "print(y_train_under.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# 2️⃣ MODELO XGBOOST CON REGULARIZACIÓN LASSO (L1)\n",
    "# ===============================================\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Regularización L1 se controla con reg_alpha > 0\n",
    "xgb_lasso = Pipeline(steps=[\n",
    "    ('prep', preprocessing_pipeline),\n",
    "    ('clf', XGBClassifier(\n",
    "        n_estimators=300, max_depth=4, learning_rate=0.1,\n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        reg_lambda=0, reg_alpha=10,               # Lasso (L1)\n",
    "        eval_metric=\"auc\", random_state=seed\n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"Modelo XGBoost con regularización L1 configurado ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# 3️⃣ VALIDACIÓN CRUZADA (STRATIFIED K-FOLD)\n",
    "# ===============================================\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, average_precision_score\n",
    "import numpy as np\n",
    "\n",
    "# Se define validación cruzada estratificada (mantiene proporciones de clases)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "# Vector para guardar probabilidades OOF (out-of-fold)\n",
    "oof_proba = np.zeros(len(y_train_under), dtype=float)\n",
    "\n",
    "for tr_idx, va_idx in cv.split(X_train_under, y_train_under):\n",
    "    xtr, xva = X_train_under.iloc[tr_idx], X_train_under.iloc[va_idx]\n",
    "    ytr, yva = y_train_under.iloc[tr_idx], y_train_under.iloc[va_idx]\n",
    "    \n",
    "    xgb_lasso.fit(xtr, ytr)\n",
    "    oof_proba[va_idx] = xgb_lasso.predict_proba(xva)[:, 1]\n",
    "\n",
    "# Calcular AUC promedio de la validación cruzada\n",
    "auc_cv = roc_auc_score(y_train_under, oof_proba)\n",
    "ap_cv  = average_precision_score(y_train_under, oof_proba)\n",
    "\n",
    "print(f\"AUC promedio CV: {auc_cv:.3f}\")\n",
    "print(f\"Average Precision (PR-AUC) CV: {ap_cv:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# 4️⃣ OPTIMIZACIÓN DEL UMBRAL (THRESHOLD)\n",
    "# ===============================================\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Calculamos curva Precision-Recall\n",
    "prec, rec, thr = precision_recall_curve(y_train_under, oof_proba)\n",
    "f1 = 2 * prec * rec / (prec + rec + 1e-12)\n",
    "thr_candidates = np.r_[thr, 1.0]  # Alinear longitudes\n",
    "\n",
    "# Seleccionamos el umbral que maximiza el F1\n",
    "idx_opt = np.nanargmax(f1)\n",
    "thr_opt = float(thr_candidates[idx_opt])\n",
    "\n",
    "print(f\"Umbral óptimo seleccionado: {thr_opt:.3f}\")\n",
    "print(f\"F1 óptimo: {f1[idx_opt]:.3f} | Precisión: {prec[idx_opt]:.3f} | Recall: {rec[idx_opt]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# 5️⃣ REENTRENAMIENTO Y EVALUACIÓN FINAL EN TEST\n",
    "# ===============================================\n",
    "\n",
    "# Entrenamos el modelo con todos los datos balanceados\n",
    "xgb_lasso.fit(X_train_under, y_train_under)\n",
    "\n",
    "# Calculamos probabilidades y predicciones en Test con el umbral óptimo\n",
    "proba_test = xgb_lasso.predict_proba(X_test)[:, 1]\n",
    "pred_test  = (proba_test >= thr_opt).astype(int)\n",
    "\n",
    "# Evaluamos con la función definida previamente\n",
    "metrics_xgb_lasso_opt = evaluar_modelo(xgb_lasso, X_train_under, y_train_under, X_test, y_test, nombre=\"XGBoost Lasso (L1) – Threshold Óptimo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "defi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
